{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "https://www.youtube.com/watch?v=yH1cF7GnoIo    \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/tensorflow-tutorial    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "\n",
    "# to display confusion matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aux functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == classNames\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [32,32])\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label\n",
    "\n",
    "def show_data(s1,l1, s2,l2, labels, min):\n",
    "    fig, ax = plt.subplots()\n",
    "    X = np.arange(len(s1))\n",
    "\n",
    "    models = labels\n",
    "    plt.bar(X, s1, width = 0.4, color = 'b', label=l1)\n",
    "    plt.bar(X + 0.4, s2, color = 'r', width = 0.4, label = l2)\n",
    "    plt.xticks(X + 0.4 / 2, models)\n",
    "    plt.ylim(top = 100, bottom = min)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "  columns = 6\n",
    "  rows = BATCH_SIZE / columns + 1  \n",
    "  plt.figure(figsize=(10, 2 * rows))\n",
    "  for n in range(BATCH_SIZE):\n",
    "      ax = plt.subplot(int(rows), columns, n+1)\n",
    "      plt.imshow((image_batch[n]))\n",
    "      plt.title(classNames[label_batch[n]==1][0])\n",
    "      plt.axis('off')\n",
    "\n",
    "\n",
    "def show_history(history):\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='lower right')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "def show_accuracies(labels, test, val): \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    X = np.arange(len(test))\n",
    "\n",
    "    plt.bar(X, test, width = 0.4, color = 'b', label='test')\n",
    "    plt.bar(X + 0.4, val, color = 'r', width = 0.4, label = \"val\")\n",
    "    plt.xticks(X + 0.4 / 2, labels)\n",
    "    plt.ylim(top = 1.0, bottom = 0.97)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "\n",
    "def show_misclassified(predictions, ground_truth, images, num_rows = 5, num_cols=3):\n",
    "    \n",
    "    # Plot the first X test images with wrong predictions.\n",
    "    num_images = num_rows*num_cols\n",
    "    print(num_images)\n",
    "    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "    i = 0\n",
    "    k = 0\n",
    "    while k < len(images) and i < num_images:\n",
    "        predicted_label = np.argmax(predictions[k])\n",
    "        gt = np.where(ground_truth[k])[0][0]\n",
    "        if predicted_label != gt:\n",
    "            plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "            plot_image(k, predictions[k], gt, images)\n",
    "            plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "            plot_value_array(k, predictions[k], ground_truth)\n",
    "            i += 1\n",
    "        k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, true_label, img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "      color = 'blue'\n",
    "    else:\n",
    "      color = 'red'\n",
    "    \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(classNames[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                classNames[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(8))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(8), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[np.where(true_label)[0][0]].set_color('blue')   \n",
    "\n",
    "\n",
    "\n",
    "def show_confusion_matrix(mat, classes):\n",
    "\n",
    "    df_cm = pd.DataFrame(mat, range(classes), range(classes))\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d') # font size\n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def prepare_callbacks(file_path):\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath= file_path, \n",
    "                               monitor = 'val_accuracy',\n",
    "                               verbose=1, \n",
    "                               save_weights_only=True,\n",
    "                               save_best_only=True)\n",
    "\n",
    "\n",
    "    earlyStopper = EarlyStopping(monitor='val_loss', min_delta = 0.0001, patience = 15, verbose = 1)\n",
    "\n",
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.000000001, verbose = 1)\n",
    "\n",
    "    return [checkpointer, earlyStopper, reduceLR]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size\n",
    "\n",
    "Batch size is an important parameter when training a network. It can influence speed and generalization, not necessarily in the same direction. There is no golden rule for the batch size but 32 is a commom number to start with.\n",
    "\n",
    "In here we go to 64 to achieve faster training epochs (rather than 32)\n",
    "\n",
    "See: https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare to load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('../gtsrb/train_images/')\n",
    "  \n",
    "classNames = np.array(os.listdir(data_dir))\n",
    "classNames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images takes place in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "listset = tf.data.Dataset.list_files(\"../gtsrb/train_images/*/*.png\")\n",
    "dataset = listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about image shape and size of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = next(iter(dataset))\n",
    "print(t[0].shape, t[1].shape)\n",
    "\n",
    "# note: this only works if dataset is not repeating\n",
    "dataset_length = tf.data.experimental.cardinality(dataset).numpy()\n",
    "print(\"Total images in dataset: \", dataset_length)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version I - training with dataset only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dataSolo = dataset\n",
    "dataSolo = dataSolo.cache()\n",
    "dataSolo = dataSolo.shuffle(buffer_size = dataset_length)\n",
    "dataSolo = dataSolo.prefetch(buffer_size=10200)\n",
    "dataSolo = dataSolo.batch(batch_size=BATCH_SIZE)\n",
    "dataSolo = dataSolo.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_listset = tf.data.Dataset.list_files(\"../gtsrb/val_images/*/*.png\")\n",
    "val_dataset_length = val_listset.cardinality().numpy()\n",
    "print(\"Total images in validatation dataset: \", val_dataset_length)\n",
    "\n",
    "valset = val_listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "valset = valset.cache()\n",
    "valset = valset.shuffle(buffer_size = 2580)\n",
    "valset = valset.batch(batch_size = 2580)\n",
    "valset = valset.prefetch(buffer_size = AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_listset = tf.data.Dataset.list_files(\"../gtsrb/test_images_per_folder/*/*.png\")\n",
    "test_dataset_length = test_listset.cardinality().numpy()\n",
    "print(\"Total images in validatation dataset: \", test_dataset_length)\n",
    "\n",
    "testset = test_listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "testset = testset.batch(batch_size = BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a batch of training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "        \n",
    "        \n",
    "image_batch, label_batch = next(iter(dataSolo))        \n",
    "show_batch(image_batch, label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def model_VI(classCount, imgSize, channels):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(128, (5, 5),\n",
    "                     input_shape=(imgSize, imgSize, channels)))         \n",
    "    model.add(LeakyReLU(alpha=0.01))  \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5)) \n",
    "\n",
    "    model.add(Conv2D(196, (5, 5) )) \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5)) \n",
    "\n",
    "    model.add(Conv2D(256, (5, 5) ) )   \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5)) \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(LeakyReLU(alpha=0.0)) \n",
    "    model.add(Dense(384))\n",
    "    model.add(LeakyReLU(alpha=0.0))             \n",
    "    model.add(Dropout(0.5)) \n",
    "    \n",
    "    model.add(Dense(classCount, activation='softmax'))\n",
    "\n",
    "    \n",
    "    opt = Adam(lr=0.0001)\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ 'accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "modelV1 = model_VI(8, 32, 3)\n",
    "\n",
    "print(modelV1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "file_pathV1 = 'd:\\\\temp\\\\best_modelV1\\\\cp.ckpt'\n",
    "\n",
    "callbacksV1 = prepare_callbacks(file_pathV1)\n",
    "\n",
    "historyV1 = modelV1.fit(dataSolo, steps_per_epoch = 10200/BATCH_SIZE,\n",
    "          epochs=50, \n",
    "          validation_data = valset, \n",
    "          callbacks = callbacksV1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "show_history(historyV1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "modelV1.load_weights(file_pathV1)\n",
    "\n",
    "evalV1 = modelV1.evaluate(testset, verbose=2)\n",
    "valV1 = modelV1.evaluate(valset, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version II - dynamic data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to transform image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#https://www.tensorflow.org/api_docs/python/tf/image\n",
    "#https://www.tensorflow.org/addons/api_docs/python/tfa/image\n",
    "\n",
    "#pip install tensorflow-addons\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "def process_image(image, label):\n",
    "    \n",
    "    # random rotate 5 degrees\n",
    "    r = tf.random.uniform(shape=(), minval=-0.175, maxval=0.175, dtype=tf.dtypes.float32)\n",
    "    image = tfa.image.rotate(image, r)\n",
    "\n",
    "    # translate image up to 10%\n",
    "    rx = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32) \n",
    "    ry = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32) \n",
    "    image = tfa.image.translate(image, [rx, ry])\n",
    "   \n",
    "    # change hue, saturation and value\n",
    "    image = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.2, 0.4, 1.1, 0.4, 1.1),0,1)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataV2 = dataset\n",
    "dataV2 = dataV2.cache()\n",
    "dataV2 = dataV2.shuffle(buffer_size = dataset_length)\n",
    "dataV2 = dataV2.map(process_image)\n",
    "dataV2 = dataV2.prefetch(buffer_size=10200)\n",
    "dataV2 = dataV2.batch(batch_size=BATCH_SIZE)\n",
    "dataV2 = dataV2.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "modelV2 = model_VI(8, 32, 3)\n",
    "\n",
    "file_pathV2 = 'd:\\\\temp\\\\best_modelV2\\\\cp.ckpt'\n",
    "\n",
    "callbacksV2 = prepare_callbacks(file_pathV2)\n",
    "\n",
    "historyV2 = modelV2.fit(dataV2, steps_per_epoch = 10200/BATCH_SIZE,\n",
    "          epochs=50, \n",
    "          validation_data = valset, \n",
    "          callbacks = callbacksV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "show_history(historyV2)\n",
    "\n",
    "modelV2.load_weights(file_pathV2)\n",
    "\n",
    "evalV2 = modelV2.evaluate(testset, verbose=2)\n",
    "valV2 = modelV2.evaluate(valset, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version III - Massive data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def process_brightness(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 1.0, 0.1, 3.0),0,1)\n",
    "    return img, label\n",
    "\n",
    "def process_saturation(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 3.0, 1.0, 1.0),0,1)\n",
    "    return img, label\n",
    "\n",
    "def process_contrast(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tf.image.random_contrast(image, lower=0.1, upper=3.0, seed=None), 0, 1)\n",
    "    return img, label\n",
    "\n",
    "def process_hue(image, label):\n",
    "    \n",
    "    img = tf.image.random_hue(image, max_delta=0.2, seed=None)\n",
    "    return img, label\n",
    "\n",
    "def process_rotate(image, label):\n",
    "    \n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    return img, label\n",
    "\n",
    "def process_shear(image, label):\n",
    "    \n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    sx = tf.random.uniform(shape=(), minval=-0.1, maxval=0.1, dtype=tf.dtypes.float32)\n",
    "    img = tfa.image.transform(img, [1, sx, -sx*32,   0,1,0,  0,0])\n",
    "    return img, label\n",
    "\n",
    "def process_translate(image, label):\n",
    "\n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    tx = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)\n",
    "    ty = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)  \n",
    "    img = tfa.image.translate(img, [tx,ty])\n",
    "    return img, label\n",
    "\n",
    "def process_crop(image, label):\n",
    "    \n",
    "    c = tf.random.uniform(shape=(), minval=24, maxval=32, dtype=tf.dtypes.float32)\n",
    "    img = tf.image.random_crop(image, size=[c,c,3])\n",
    "    img = tf.image.resize(img ,size= [32,32])\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataV3 = dataset\n",
    "# color ops\n",
    "dataV3 = dataV3.map(process_brightness)\n",
    "dataV3 = dataV3.concatenate(dataset.map(process_contrast))\n",
    "dataV3 = dataV3.concatenate(dataset.map(process_hue))\n",
    "dataV3 = dataV3.concatenate(dataset.map(process_saturation))\n",
    "\n",
    "#geometry ops\n",
    "dataV3 = dataV3.concatenate(dataset.map(process_rotate))\n",
    "dataV3 = dataV3.concatenate(dataset.map(process_shear))\n",
    "dataV3 = dataV3.concatenate(dataset.map(process_translate))\n",
    "dataV3 = dataV3.concatenate(dataset.map(process_crop))\n",
    "\n",
    "dataV3 = dataV3.cache()\n",
    "dataV3 = dataV3.shuffle(buffer_size = 81600)\n",
    "dataV3 = dataV3.batch(batch_size = BATCH_SIZE)\n",
    "dataV3 = dataV3.prefetch(buffer_size = AUTOTUNE)\n",
    "dataV3 = dataV3.repeat()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "modelV3 = model_VI(8, 32, 3)\n",
    "\n",
    "file_pathV3 = 'd:\\\\temp\\\\best_modelV3\\\\cp.ckpt'\n",
    "\n",
    "callbacksV3 = prepare_callbacks(file_pathV3)\n",
    "\n",
    "historyV3 = modelV3.fit(dataV3, steps_per_epoch = 81600/BATCH_SIZE,\n",
    "          epochs=50, \n",
    "          validation_data = valset, \n",
    "          callbacks = callbacksV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "show_history(historyV3)\n",
    "\n",
    "modelV3.load_weights(file_pathV3)\n",
    "\n",
    "evalV3 = modelV3.evaluate(testset, verbose=2)\n",
    "valV3 = modelV3.evaluate(valset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "show_accuracies(['V1', 'V2', 'V3'], [evalV1[1], evalV2[1], evalV3[1]], [valV1[1], valV2[1], valV3[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "numpy_labels = []\n",
    "numpy_images = []\n",
    "pred = []\n",
    "\n",
    "for images, labels in testset.take(-1):  # take all batches of dataset\n",
    "    numpy_images.extend(images.numpy())\n",
    "    numpy_labels.extend(labels.numpy())\n",
    "    pred.extend(modelV3.predict(images.numpy()))\n",
    "\n",
    "\n",
    "show_misclassified(pred, numpy_labels, numpy_images, int((4170 - 4170*.994)/3 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_labels = [np.argmax(x) for x in numpy_labels]\n",
    "all_preds = [np.argmax(x) for x in pred]\n",
    "    \n",
    "conf_mat = tf.math.confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "show_confusion_matrix(conf_mat.numpy(), 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
