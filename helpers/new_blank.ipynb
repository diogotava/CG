{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "configured-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "\n",
    "# to display confusion matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indie-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == classNames\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [32,32])\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label\n",
    "\n",
    "def show_data(s1,l1, s2,l2, labels, min):\n",
    "    fig, ax = plt.subplots()\n",
    "    X = np.arange(len(s1))\n",
    "\n",
    "    models = labels\n",
    "    plt.bar(X, s1, width = 0.4, color = 'b', label=l1)\n",
    "    plt.bar(X + 0.4, s2, color = 'r', width = 0.4, label = l2)\n",
    "    plt.xticks(X + 0.4 / 2, models)\n",
    "    plt.ylim(top = 100, bottom = min)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "  columns = 6\n",
    "  rows = BATCH_SIZE / columns + 1  \n",
    "  plt.figure(figsize=(10, 2 * rows))\n",
    "  for n in range(BATCH_SIZE):\n",
    "      ax = plt.subplot(int(rows), columns, n+1)\n",
    "      plt.imshow((image_batch[n]))\n",
    "      plt.title(classNames[label_batch[n]==1][0])\n",
    "      plt.axis('off')\n",
    "\n",
    "\n",
    "def show_history(history):\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='lower right')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "def show_accuracies(labels, test, val): \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    X = np.arange(len(test))\n",
    "\n",
    "    plt.bar(X, test, width = 0.4, color = 'b', label='test')\n",
    "    plt.bar(X + 0.4, val, color = 'r', width = 0.4, label = \"val\")\n",
    "    plt.xticks(X + 0.4 / 2, labels)\n",
    "    plt.ylim(top = 1.0, bottom = 0.97)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "\n",
    "def show_misclassified(predictions, ground_truth, images, num_rows = 5, num_cols=3):\n",
    "    \n",
    "    # Plot the first X test images with wrong predictions.\n",
    "    num_images = num_rows*num_cols\n",
    "    print(num_images)\n",
    "    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "    i = 0\n",
    "    k = 0\n",
    "    while k < len(images) and i < num_images:\n",
    "        predicted_label = np.argmax(predictions[k])\n",
    "        gt = np.where(ground_truth[k])[0][0]\n",
    "        if predicted_label != gt:\n",
    "            plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "            plot_image(k, predictions[k], gt, images)\n",
    "            plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "            plot_value_array(k, predictions[k], ground_truth)\n",
    "            i += 1\n",
    "        k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, true_label, img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "      color = 'blue'\n",
    "    else:\n",
    "      color = 'red'\n",
    "    \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(classNames[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                classNames[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(8))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(8), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[np.where(true_label)[0][0]].set_color('blue')   \n",
    "\n",
    "\n",
    "\n",
    "def show_confusion_matrix(mat, classes):\n",
    "\n",
    "    df_cm = pd.DataFrame(mat, range(classes), range(classes))\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d') # font size\n",
    "\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "flexible-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_callbacks(file_path):\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath= file_path, \n",
    "                               monitor = 'val_accuracy',\n",
    "                               verbose=1, \n",
    "                               save_weights_only=True,\n",
    "                               save_best_only=True)\n",
    "\n",
    "\n",
    "    earlyStopper = EarlyStopping(monitor='val_loss', min_delta = 0.0001, patience = 15, verbose = 1)\n",
    "\n",
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.000000001, verbose = 1)\n",
    "\n",
    "    return [checkpointer, earlyStopper, reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "personalized-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "drawn-bundle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00000', '00001', '00002', '00003', '00004', '00005', '00006',\n",
       "       '00007', '00008', '00009', '00010', '00011', '00012', '00013',\n",
       "       '00014', '00015', '00016', '00017', '00018', '00019', '00020',\n",
       "       '00021', '00022', '00023', '00024', '00025', '00026', '00027',\n",
       "       '00028', '00029', '00030', '00031', '00032', '00033', '00034',\n",
       "       '00035', '00036', '00037', '00038', '00039', '00040', '00041',\n",
       "       '00042'], dtype='<U5')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path('../Final_Training/Images/')\n",
    "  \n",
    "classNames = np.array(os.listdir(data_dir))\n",
    "classNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "listset = tf.data.Dataset.list_files(\"../Final_Training/Images/*/*.png\")\n",
    "dataset = listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "\n",
    "t = next(iter(dataset))\n",
    "print(t[0].shape, t[1].shape)\n",
    "\n",
    "dataset_length = tf.data.experimental.cardinality(dataset).numpy()\n",
    "print(\"Total images in dataset: \", dataset_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "primary-princess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in validatation dataset:  11280\n",
      "Total images in test dataset:  12630\n"
     ]
    }
   ],
   "source": [
    "val_listset = tf.data.Dataset.list_files(\"../Final_Validation/Images/*/*.png\")\n",
    "val_dataset_length = val_listset.cardinality().numpy()\n",
    "print(\"Total images in validatation dataset: \", val_dataset_length)\n",
    "\n",
    "valset = val_listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "valset = valset.cache()\n",
    "valset = valset.shuffle(buffer_size = val_dataset_length)\n",
    "valset = valset.batch(batch_size = BATCH_SIZE)\n",
    "valset = valset.prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "\n",
    "test_listset = tf.data.Dataset.list_files(\"../Final_Test/Images/*/*.png\")\n",
    "test_dataset_length = test_listset.cardinality().numpy()\n",
    "print(\"Total images in test dataset: \", test_dataset_length)\n",
    "\n",
    "testset = test_listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "testset = testset.batch(batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unexpected-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_VI(classCount, imgSize, channels):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    #128\n",
    "    model.add(Conv2D(128, (5, 5),\n",
    "                     input_shape=(imgSize, imgSize, channels)))         \n",
    "    model.add(LeakyReLU(alpha=0.01))  \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5)) \n",
    "\n",
    "    #196\n",
    "    model.add(Conv2D(196, (5, 5) )) \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5)) \n",
    "\n",
    "    #256\n",
    "    model.add(Conv2D(256, (5, 5) ) )   \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5)) \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(LeakyReLU(alpha=0.0)) \n",
    "    model.add(Dense(384))\n",
    "    model.add(LeakyReLU(alpha=0.0))             \n",
    "    model.add(Dropout(0.5)) \n",
    "    \n",
    "    model.add(Dense(classCount, activation='softmax'))\n",
    "\n",
    "    \n",
    "    opt = Adam(lr=0.0001)\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ 'accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-reduction",
   "metadata": {},
   "source": [
    "### Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bacterial-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def process_brightness(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 1.0, 0.1, 3.0),0,1)\n",
    "    return img, label\n",
    "\n",
    "def process_saturation(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 3.0, 1.0, 1.0),0,1)\n",
    "    return img, label\n",
    "\n",
    "def process_contrast(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tf.image.random_contrast(image, lower=0.1, upper=3.0, seed=None), 0, 1)\n",
    "    return img, label\n",
    "\n",
    "def process_hue(image, label):\n",
    "    \n",
    "    img = tf.image.random_hue(image, max_delta=0.2, seed=None)\n",
    "    return img, label\n",
    "\n",
    "def process_rotate(image, label):\n",
    "    \n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    return img, label\n",
    "\n",
    "def process_shear(image, label):\n",
    "    \n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    sx = tf.random.uniform(shape=(), minval=-0.1, maxval=0.1, dtype=tf.dtypes.float32)\n",
    "    img = tfa.image.transform(img, [1, sx, -sx*32,   0,1,0,  0,0])\n",
    "    return img, label\n",
    "\n",
    "def process_translate(image, label):\n",
    "\n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    tx = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)\n",
    "    ty = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)  \n",
    "    img = tfa.image.translate(img, [tx,ty])\n",
    "    return img, label\n",
    "\n",
    "def process_crop(image, label):\n",
    "    \n",
    "    c = tf.random.uniform(shape=(), minval=24, maxval=32, dtype=tf.dtypes.float32)\n",
    "    img = tf.image.random_crop(image, size=[c,c,3])\n",
    "    img = tf.image.resize(img ,size= [32,32])\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "utility-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataV1 = dataset\n",
    "# color ops\n",
    "dataV1 = dataV1.map(process_brightness)\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_contrast))\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_hue))\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_saturation))\n",
    "\n",
    "#geometry ops\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_rotate))\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_shear))\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_translate))\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_crop))\n",
    "\n",
    "dataV1 = dataV1.cache()\n",
    "dataV1 = dataV1.shuffle(buffer_size = (dataset_length * 8))\n",
    "dataV1 = dataV1.batch(batch_size = BATCH_SIZE)\n",
    "dataV1 = dataV1.prefetch(buffer_size = AUTOTUNE)\n",
    "dataV1 = dataV1.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelV1 = model_VI(43, 32, 3)\n",
    "\n",
    "file_pathV1 = 'best_modelV1/cp.ckpt'\n",
    "\n",
    "callbacksV1 = prepare_callbacks(file_pathV1)\n",
    "\n",
    "historyV1 = modelV1.fit(dataV1, steps_per_epoch = dataset_length * 8 / BATCH_SIZE,\n",
    "          epochs=50, \n",
    "          validation_data = valset, \n",
    "          callbacks = callbacksV1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(historyV1)\n",
    "\n",
    "modelV1.load_weights(file_pathV1)\n",
    "\n",
    "evalV1 = modelV1.evaluate(testset, verbose=2)\n",
    "# valV1 = modelV1.evaluate(valset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_labels = []\n",
    "numpy_images = []\n",
    "pred = []\n",
    "\n",
    "for images, labels in testset.take(-1):  # take all batches of dataset\n",
    "    numpy_images.extend(images.numpy())\n",
    "    numpy_labels.extend(labels.numpy())\n",
    "    pred.extend(modelV1.predict(images.numpy()))\n",
    "\n",
    "\n",
    "show_misclassified(pred, numpy_labels, numpy_images, int((test_dataset_length - test_dataset_length*.994)/3 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [np.argmax(x) for x in numpy_labels]\n",
    "all_preds = [np.argmax(x) for x in pred]\n",
    "    \n",
    "conf_mat = tf.math.confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "show_confusion_matrix(conf_mat.numpy(), 43)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
