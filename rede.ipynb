{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suited-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "\n",
    "# to determine the most voted\n",
    "import collections \n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "overhead-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == classNames\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [32,32])\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "  columns = 6\n",
    "  rows = BATCH_SIZE / columns + 1  \n",
    "  plt.figure(figsize=(10, 2 * rows))\n",
    "  for n in range(BATCH_SIZE):\n",
    "      ax = plt.subplot(int(rows), columns, n+1)\n",
    "      plt.imshow((image_batch[n]))\n",
    "      plt.title(classNames[label_batch[n]==1][0])\n",
    "      plt.axis('off')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cleared-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_callbacks(file_path):\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath= file_path, \n",
    "                               monitor = 'val_accuracy',\n",
    "                               verbose=1, \n",
    "                               save_weights_only=True,\n",
    "                               save_best_only=True)\n",
    "\n",
    "\n",
    "    earlyStopper = EarlyStopping(monitor='val_loss', min_delta = 0.0001, patience = 15, verbose = 1)\n",
    "\n",
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.000000001, verbose = 1)\n",
    "\n",
    "    return [checkpointer, earlyStopper, reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "processed-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 32\n",
    "NUM_MODELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "instrumental-amplifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00000', '00001', '00002', '00003', '00004', '00005', '00006',\n",
       "       '00007', '00008', '00009', '00010', '00011', '00012', '00013',\n",
       "       '00014', '00015', '00016', '00017', '00018', '00019', '00020',\n",
       "       '00021', '00022', '00023', '00024', '00025', '00026', '00027',\n",
       "       '00028', '00029', '00030', '00031', '00032', '00033', '00034',\n",
       "       '00035', '00036', '00037', '00038', '00039', '00040', '00041',\n",
       "       '00042'], dtype='<U5')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path('Final_Training/Images/')\n",
    "  \n",
    "classNames = np.array(os.listdir(data_dir))\n",
    "NUM_CLASSES = len(classNames)\n",
    "classNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "musical-mouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3) (43,)\n",
      "Total images in dataset:  27930\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "listset = tf.data.Dataset.list_files(\"Final_Training/Images/*/*.png\")\n",
    "dataset = listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "\n",
    "t = next(iter(dataset))\n",
    "print(t[0].shape, t[1].shape)\n",
    "\n",
    "dataset_length = tf.data.experimental.cardinality(dataset).numpy()\n",
    "print(\"Total images in dataset: \", dataset_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "boxed-passenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in validatation dataset:  11280\n",
      "Total images in test dataset:  12630\n"
     ]
    }
   ],
   "source": [
    "val_listset = tf.data.Dataset.list_files(\"Final_Validation/Images/*/*.png\")\n",
    "val_dataset_length = val_listset.cardinality().numpy()\n",
    "print(\"Total images in validatation dataset: \", val_dataset_length)\n",
    "\n",
    "valset = val_listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "valset = valset.cache()\n",
    "valset = valset.shuffle(buffer_size = val_dataset_length)\n",
    "valset = valset.batch(batch_size = BATCH_SIZE)\n",
    "valset = valset.prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "\n",
    "test_listset = tf.data.Dataset.list_files(\"Final_Test/Images/*/*.png\")\n",
    "test_dataset_length = test_listset.cardinality().numpy()\n",
    "print(\"Total images in test dataset: \", test_dataset_length)\n",
    "\n",
    "testset = test_listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "testset = testset.batch(batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incomplete-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(classCount, imgSize, channels):\n",
    "\n",
    "    modelLogits = Sequential()\n",
    "    \n",
    "    modelLogits.add(Conv2D(128, (5, 5),\n",
    "                input_shape=(imgSize, imgSize, channels)))         \n",
    "    modelLogits.add(LeakyReLU(alpha=0.01))  \n",
    "    modelLogits.add(BatchNormalization())\n",
    "    modelLogits.add(Dropout(0.5)) \n",
    "\n",
    "    modelLogits.add(Conv2D(196, (5, 5) )) \n",
    "    modelLogits.add(LeakyReLU(alpha=0.01))\n",
    "    modelLogits.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    modelLogits.add(BatchNormalization())\n",
    "    modelLogits.add(Dropout(0.5)) \n",
    "\n",
    "    modelLogits.add(Conv2D(256, (5, 5) ) )   \n",
    "    modelLogits.add(LeakyReLU(alpha=0.01))\n",
    "    modelLogits.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    modelLogits.add(BatchNormalization())\n",
    "    modelLogits.add(Dropout(0.5)) \n",
    "    \n",
    "    modelLogits.add(Flatten())\n",
    "    modelLogits.add(Dense(384))\n",
    "    modelLogits.add(LeakyReLU(alpha=0.0))             \n",
    "    modelLogits.add(Dropout(0.5)) \n",
    "    \n",
    "    modelLogits.add(Dense(classCount))\n",
    "    \n",
    "    output = Activation('softmax')(modelLogits.output)\n",
    "\n",
    "    model = tf.keras.Model(modelLogits.inputs, output)\n",
    "    \n",
    "    opt = Adam(lr=0.0001)\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ 'accuracy'])\n",
    "    return model, modelLogits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-checkout",
   "metadata": {},
   "source": [
    "### Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "changing-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def process_brightness(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 1.0, 0.1, 3.0),0,1)\n",
    "    return img, label\n",
    "\n",
    "def process_saturation(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 3.0, 1.0, 1.0),0,1)\n",
    "    return img, label\n",
    "\n",
    "def process_contrast(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tf.image.random_contrast(image, lower=0.1, upper=3.0, seed=None), 0, 1)\n",
    "    return img, label\n",
    "\n",
    "def process_hue(image, label):\n",
    "    \n",
    "    img = tf.image.random_hue(image, max_delta=0.2, seed=None)\n",
    "    return img, label\n",
    "\n",
    "def process_rotate(image, label):\n",
    "    \n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    return img, label\n",
    "\n",
    "def process_shear(image, label):\n",
    "    \n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    sx = tf.random.uniform(shape=(), minval=-0.1, maxval=0.1, dtype=tf.dtypes.float32)\n",
    "    img = tfa.image.transform(img, [1, sx, -sx*32,   0,1,0,  0,0])\n",
    "    return img, label\n",
    "\n",
    "def process_translate(image, label):\n",
    "\n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    tx = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)\n",
    "    ty = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)  \n",
    "    img = tfa.image.translate(img, [tx,ty])\n",
    "    return img, label\n",
    "\n",
    "def process_crop(image, label):\n",
    "    \n",
    "    c = tf.random.uniform(shape=(), minval=24, maxval=32, dtype=tf.dtypes.float32)\n",
    "    img = tf.image.random_crop(image, size=[c,c,3])\n",
    "    img = tf.image.resize(img ,size= [32,32])\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-fraud",
   "metadata": {},
   "source": [
    "### Ensemble functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adverse-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train, val,file_path_prefix, new_length):\n",
    "    models = []\n",
    "    histories = []\n",
    "    \n",
    "    for i in range(NUM_MODELS):\n",
    "\n",
    "        model, modelL = create_model(NUM_CLASSES,IMAGE_SIZE,3)\n",
    "\n",
    "        callbacks = prepare_callbacks(f'{file_path_prefix}_{i:02}/cp.ckpt')\n",
    "        \n",
    "        hist = model.fit(train, steps_per_epoch = new_length / BATCH_SIZE,\n",
    "                              epochs=5, \n",
    "                              validation_data = val, \n",
    "                              callbacks = callbacks)\n",
    "\n",
    "        models.append([model, modelL])\n",
    "        histories.append(hist)\n",
    "    \n",
    "    return models,histories\n",
    "\n",
    "\n",
    "def create_models():\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    for i in range(NUM_MODELS):\n",
    "        model, modelL = create_model(NUM_CLASSES,IMAGE_SIZE,3)\n",
    "        models.append([model, modelL])\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "def load_weights(models, file_path_prefix):\n",
    "    for i in range(NUM_MODELS):\n",
    "        file_path = f'{file_path_prefix}_{i:02}/cp.ckpt'\n",
    "        models[i][0].load_weights(file_path)\n",
    "        models[i][0].save('ensemble/temp.hdf5')\n",
    "        models[i][1].load_weights('ensemble/temp.hdf5', by_name = True)\n",
    "\n",
    "\n",
    "def evaluate_models(models):\n",
    "    \n",
    "    accuracy = 0\n",
    "    \n",
    "    for i in range(NUM_MODELS):\n",
    "        eval = models[i][0].evaluate(testset, verbose = 2)\n",
    "        accuracy += eval[1]\n",
    "        \n",
    "    print(f'average accuracy: {(accuracy/NUM_MODELS)*100:.3f}')\n",
    "\n",
    "    \n",
    "def get_labels_logits_and_preds(models):\n",
    "\n",
    "    preds = [[] for _ in range(NUM_MODELS) ]\n",
    "    logits = [[] for _ in range(NUM_MODELS)]\n",
    "    labels = []\n",
    "    for images, labs in testset.take(-1):\n",
    "\n",
    "        labels.extend(labs.numpy())\n",
    "        for i in range(NUM_MODELS):\n",
    "\n",
    "            preds[i].extend(models[i][0].predict(images))\n",
    "            logits[i].extend(models[i][1].predict(images))\n",
    "\n",
    "    labels = [np.argmax(i) for i in labels]  \n",
    "    \n",
    "    return labels, logits, preds\n",
    "\n",
    "\n",
    "def get_class_preds(preds):\n",
    "\n",
    "    class_preds = []\n",
    "\n",
    "    for i in range(test_dataset_length):\n",
    "\n",
    "        c = []\n",
    "        for m in range(NUM_MODELS):\n",
    "\n",
    "            c.append(np.argmax(preds[m][i]))\n",
    "        class_preds.append(c)\n",
    "        \n",
    "    return class_preds\n",
    "\n",
    "\n",
    "def get_class_from_sum_of_logits(logits):\n",
    "\n",
    "    sum_logits = []\n",
    "\n",
    "    for i in range(test_dataset_length):\n",
    "\n",
    "        log = logits[0][i]\n",
    "        for m in range(1, NUM_MODELS):\n",
    "            log = np.add(log, logits[m][i])\n",
    "        sum_logits.append(np.argmax(log))\n",
    "    return(sum_logits)\n",
    "\n",
    "\n",
    "def get_stats(labels, class_preds, class_logits):\n",
    "\n",
    "    all_correct = 0\n",
    "    all_incorrect = 0\n",
    "    maj_vote = 0\n",
    "    maj_wrong = 0\n",
    "    tie = 0\n",
    "    count = 0\n",
    "    log_ok = 0\n",
    "    log_ko = 0\n",
    "\n",
    "    for k in range(test_dataset_length):\n",
    "\n",
    "        counter = collections.Counter(class_preds[k])\n",
    "        if len(counter) == 1:\n",
    "            if counter.most_common(1)[0][0] == labels[k]:\n",
    "                all_correct += 1\n",
    "            else:\n",
    "                all_incorrect += 1\n",
    "        else:\n",
    "            aux = counter.most_common(2)\n",
    "            if aux[0][1] > aux[1][1] and aux[0][0] == labels[k]:\n",
    "                maj_vote += 1\n",
    "            if aux[0][1] > aux[1][1] and aux[0][0] != labels[k]:\n",
    "                maj_wrong += 1\n",
    "            elif aux[0][1] == aux[1][1]:\n",
    "                tie += 1\n",
    "        if class_logits[k] == labels[k]:\n",
    "            log_ok += 1\n",
    "        else:\n",
    "            log_ko += 1\n",
    "        count += 1 \n",
    "        \n",
    "    return [count, all_correct, all_incorrect, maj_vote, tie, maj_wrong, log_ok, log_ko]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-worst",
   "metadata": {},
   "source": [
    "### Dataset augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "municipal-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataV1 = dataset\n",
    "# color ops\n",
    "dataV1 = dataV1.map(process_brightness)\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_contrast))\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_hue))\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_saturation))\n",
    "\n",
    "#geometry ops\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_rotate))\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_shear))\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_translate))\n",
    "dataV1 = dataV1.concatenate(dataset.map(process_crop))\n",
    "\n",
    "# number of dataset augmentation functions used\n",
    "dataset_updated_length = dataset_length * 8\n",
    "\n",
    "dataV1 = dataV1.cache()\n",
    "dataV1 = dataV1.shuffle(buffer_size = (dataset_updated_length))\n",
    "dataV1 = dataV1.batch(batch_size = BATCH_SIZE)\n",
    "dataV1 = dataV1.prefetch(buffer_size = AUTOTUNE)\n",
    "dataV1 = dataV1.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_prefix = 'ensemble/model_V1'\n",
    "models_V1, histories_V1 = train_models(dataV1, valset, file_path_prefix, dataset_updated_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "close-passage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 - 1s - loss: 0.0418 - accuracy: 0.9875\n",
      "99/99 - 1s - loss: 0.0361 - accuracy: 0.9900\n",
      "99/99 - 1s - loss: 0.0359 - accuracy: 0.9897\n",
      "average accuracy: 98.907\n",
      "[12630, 12411, 49, 98, 21, 51, 12520, 110] 0.9912905779889153\n"
     ]
    }
   ],
   "source": [
    "load_weights(models_V1, file_path_prefix)\n",
    "evaluate_models(models_V1)\n",
    "labels_V1, logits_V1, preds_V1 = get_labels_logits_and_preds(models_V1)\n",
    "class_preds_V1 = get_class_preds(preds_V1)\n",
    "class_logits_V1 = get_class_from_sum_of_logits(logits_V1)    \n",
    "\n",
    "res = get_stats(labels_V1, class_preds_V1, class_logits_V1)\n",
    "print(res, res[6]/res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "consecutive-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[count, all_correct, all_incorrect, maj_vote, tie, maj_wrong, log_ok, log_ko], accuracy\n",
      "[12630, 12411, 49, 98, 21, 51, 12520, 110] 0.9912905779889153\n"
     ]
    }
   ],
   "source": [
    "res = get_stats(labels_V1, class_preds_V1, class_logits_V1)\n",
    "print('[count, all_correct, all_incorrect, maj_vote, tie, maj_wrong, log_ok, log_ko], accuracy')\n",
    "print(res, res[6]/res[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
